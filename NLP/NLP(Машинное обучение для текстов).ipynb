{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d2a07",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Оглавление<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовим-данные-для-Bert\" data-toc-modified-id=\"Подготовим-данные-для-Bert-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подготовим данные для Bert</a></span></li><li><span><a href=\"#Подготовим-данные-с-помощью-DistilBERT-base-uncased-finetuned-SST-2\" data-toc-modified-id=\"Подготовим-данные-с-помощью-DistilBERT-base-uncased-finetuned-SST-2-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовим данные с помощью DistilBERT base uncased finetuned SST-2</a></span></li><li><span><a href=\"#Подготовим-данные-для-векторизации-TF-IDF\" data-toc-modified-id=\"Подготовим-данные-для-векторизации-TF-IDF-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Подготовим данные для векторизации TF-IDF</a></span></li><li><span><a href=\"#Подготовим-данные-catboost\" data-toc-modified-id=\"Подготовим-данные-catboost-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Подготовим данные catboost</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bert\" data-toc-modified-id=\"Bert-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bert</a></span></li><li><span><a href=\"#DistilBERT-base-uncased-finetuned-SST-2\" data-toc-modified-id=\"DistilBERT-base-uncased-finetuned-SST-2-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>DistilBERT base uncased finetuned SST-2</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Catboost</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c127bd6",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb42c7",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Нужно обучить модель классифицировать комментарии на позитивные и негативные. У нас есть набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Требуется построить модель со значением метрики качества F1 не менее 0,75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33826ee2",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8748a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\i.vereschagin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\i.vereschagin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\i.vereschagin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Для начала подключим все необходимые библиотеки\n",
    "# импортируем библиотеку пандас\n",
    "import pandas as pd \n",
    "# импортируем библиотеку numpy\n",
    "import numpy as np\n",
    "# импортируем библиотеку для расчета метрик\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, f1_score, recall_score, precision_score\n",
    "# импортируем библиотеку для разбития данных на выборки, кроссвалидации\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "# импортируем библиотеку для логистической регрессии\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# импортируем библиотеку для масштабирования\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# импортируем библиотеку утилит\n",
    "from sklearn.utils import shuffle \n",
    "# импортируем библиотеку для работы с графиками\n",
    "import matplotlib.pyplot as plt \n",
    "#Библиотека для показания индикатора прогресса\n",
    "from tqdm import notebook \n",
    "#TF-IDF, «счётчик слов для создания векторов»\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "# стоп слова\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#Импортируем библиотеку сеаборн для построения множественных графиков.\n",
    "import seaborn as sns\n",
    "# Библиотека для лемматизации\n",
    "from pymystem3 import Mystem\n",
    "# Библиотека регулярных выражений\n",
    "import re \n",
    "# катбуст\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import IPython.display \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63095fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD1CAYAAABOfbKwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATbklEQVR4nO3df4ydVX7f8fendpeyWUEMDJSMvbVb3KaAWiVYXtpI1apusauN1vwB0qyaYqWWrCLSJlWrBDd/IO3KEqhVaZEKkhVcDF0BlpsKKxHZWKarVVVimP2RsIYQRmEDExyY1C6lrSAx+faPe2Z7fbk+tufaM4DfL+nRfe73Oef4XGng4+ec545TVUiSdCZ/bqUnIEn6eDMoJEldBoUkqcugkCR1GRSSpC6DQpLUtXqlJ3ChXXPNNbV+/fqVnoYkfaJ8+9vf/uOqmhp37VMXFOvXr2d2dnalpyFJnyhJ/uBM11x6kiR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnrU/eFu0+K9ff++kpP4VPlB/d/aaWnIH1qnfWOIsm+JO8k+f6Ya/8ySSW5Zqi2O8lckleTbB2q35LkpXbtoSRp9cuSPN3qR5OsH+qzI8lr7dgx8aeVJJ23c1l6egzYNlpMsg74+8AbQ7UbgRngptbn4SSr2uVHgF3AxnYsjrkTOFlVNwAPAg+0sa4C7gO+AGwG7kuy5vw+niRpUmcNiqr6FnBizKUHgV8Ehv/R7e3AU1X1QVW9DswBm5NcD1xRVc/X4B/pfhy4fajP/nZ+ENjS7ja2Aoer6kRVnQQOMyawJEkX15I2s5N8GfjDqvrtkUvTwJtD7+dbbbqdj9ZP61NVp4B3gas7Y0mSltF5b2Yn+Szwy8Bt4y6PqVWnvtQ+o3PaxWBZi89//vPjmkiSlmgpdxR/BdgA/HaSHwBrge8k+YsM/ta/bqjtWuCtVl87ps5wnySrgSsZLHWdaayPqKq9VbWpqjZNTY39deqSpCU676Coqpeq6tqqWl9V6xn8D/0nq+qPgEPATHuSaQODTesXquo48F6SW9v+w13AM23IQ8DiE013AM+1fYxvALclWdM2sW9rNUnSMjrr0lOSJ4EvAtckmQfuq6pHx7WtqmNJDgAvA6eAe6rqw3b5bgZPUF0OPNsOgEeBJ5LMMbiTmGljnUjyNeDF1u6rVTVuU12SdBGdNSiq6itnub5+5P0eYM+YdrPAzWPq7wN3nmHsfcC+s81RknTx+Cs8JEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkrrMGRZJ9Sd5J8v2h2r9O8rtJfifJf0nyo0PXdieZS/Jqkq1D9VuSvNSuPZQkrX5Zkqdb/WiS9UN9diR5rR07LtSHliSdu3O5o3gM2DZSOwzcXFV/A/g9YDdAkhuBGeCm1ufhJKtan0eAXcDGdiyOuRM4WVU3AA8CD7SxrgLuA74AbAbuS7Lm/D+iJGkSZw2KqvoWcGKk9ptVdaq9/S1gbTvfDjxVVR9U1evAHLA5yfXAFVX1fFUV8Dhw+1Cf/e38ILCl3W1sBQ5X1YmqOskgnEYDS5J0kV2IPYp/DDzbzqeBN4euzbfadDsfrZ/Wp4XPu8DVnbEkSctooqBI8svAKeDri6UxzapTX2qf0XnsSjKbZHZhYaE/aUnSeVlyULTN5Z8G/mFbToLB3/rXDTVbC7zV6mvH1E/rk2Q1cCWDpa4zjfURVbW3qjZV1aapqamlfiRJ0hhLCook24BfAr5cVf936NIhYKY9ybSBwab1C1V1HHgvya1t/+Eu4JmhPotPNN0BPNeC5xvAbUnWtE3s21pNkrSMVp+tQZIngS8C1ySZZ/Ak0m7gMuBwe8r1t6rqn1TVsSQHgJcZLEndU1UftqHuZvAE1eUM9jQW9zUeBZ5IMsfgTmIGoKpOJPka8GJr99WqOm1TXZJ08Z01KKrqK2PKj3ba7wH2jKnPAjePqb8P3HmGsfYB+842R0nSxeM3syVJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpK6zBkWSfUneSfL9odpVSQ4nea29rhm6tjvJXJJXk2wdqt+S5KV27aEkafXLkjzd6keTrB/qs6P9Ga8l2XHBPrUk6Zydyx3FY8C2kdq9wJGq2ggcae9JciMwA9zU+jycZFXr8wiwC9jYjsUxdwInq+oG4EHggTbWVcB9wBeAzcB9w4EkSVoeZw2KqvoWcGKkvB3Y3873A7cP1Z+qqg+q6nVgDtic5Hrgiqp6vqoKeHykz+JYB4Et7W5jK3C4qk5U1UngMB8NLEnSRbbUPYrrquo4QHu9ttWngTeH2s232nQ7H62f1qeqTgHvAld3xpIkLaMLvZmdMbXq1Jfa5/Q/NNmVZDbJ7MLCwjlNVJJ0bpYaFG+35STa6zutPg+sG2q3Fnir1deOqZ/WJ8lq4EoGS11nGusjqmpvVW2qqk1TU1NL/EiSpHGWGhSHgMWnkHYAzwzVZ9qTTBsYbFq/0Jan3ktya9t/uGukz+JYdwDPtX2MbwC3JVnTNrFvazVJ0jJafbYGSZ4Evghck2SewZNI9wMHkuwE3gDuBKiqY0kOAC8Dp4B7qurDNtTdDJ6guhx4th0AjwJPJJljcCcx08Y6keRrwIut3VeranRTXZJ0kZ01KKrqK2e4tOUM7fcAe8bUZ4Gbx9TfpwXNmGv7gH1nm6Mk6eLxm9mSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVLXREGR5J8nOZbk+0meTPIXklyV5HCS19rrmqH2u5PMJXk1ydah+i1JXmrXHkqSVr8sydOtfjTJ+knmK0k6f0sOiiTTwD8DNlXVzcAqYAa4FzhSVRuBI+09SW5s128CtgEPJ1nVhnsE2AVsbMe2Vt8JnKyqG4AHgQeWOl9J0tJMuvS0Grg8yWrgs8BbwHZgf7u+H7i9nW8HnqqqD6rqdWAO2JzkeuCKqnq+qgp4fKTP4lgHgS2LdxuSpOWx5KCoqj8E/g3wBnAceLeqfhO4rqqOtzbHgWtbl2ngzaEh5lttup2P1k/rU1WngHeBq5c6Z0nS+Ztk6WkNg7/xbwB+DPiRJD/T6zKmVp16r8/oXHYlmU0yu7Cw0J+4JOm8TLL09PeA16tqoar+FPhV4G8Db7flJNrrO639PLBuqP9aBktV8+18tH5an7a8dSVwYnQiVbW3qjZV1aapqakJPpIkadQkQfEGcGuSz7Z9gy3AK8AhYEdrswN4pp0fAmbak0wbGGxav9CWp95Lcmsb566RPotj3QE81/YxJEnLZPVSO1bV0SQHge8Ap4DvAnuBzwEHkuxkECZ3tvbHkhwAXm7t76mqD9twdwOPAZcDz7YD4FHgiSRzDO4kZpY6X0nS0iw5KACq6j7gvpHyBwzuLsa13wPsGVOfBW4eU3+fFjSSpJXhN7MlSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqSuiYIiyY8mOZjkd5O8kuRvJbkqyeEkr7XXNUPtdyeZS/Jqkq1D9VuSvNSuPZQkrX5Zkqdb/WiS9ZPMV5J0/ia9o/j3wG9U1Y8DfxN4BbgXOFJVG4Ej7T1JbgRmgJuAbcDDSVa1cR4BdgEb27Gt1XcCJ6vqBuBB4IEJ5ytJOk9LDookVwB/B3gUoKr+pKr+J7Ad2N+a7Qdub+fbgaeq6oOqeh2YAzYnuR64oqqer6oCHh/pszjWQWDL4t2GJGl5THJH8ZeBBeA/Jvlukl9J8iPAdVV1HKC9XtvaTwNvDvWfb7Xpdj5aP61PVZ0C3gWunmDOkqTzNElQrAZ+Enikqn4C+D+0ZaYzGHcnUJ16r8/pAye7kswmmV1YWOjPWpJ0XiYJinlgvqqOtvcHGQTH2205ifb6zlD7dUP91wJvtfraMfXT+iRZDVwJnBidSFXtrapNVbVpampqgo8kSRq15KCoqj8C3kzy11ppC/AycAjY0Wo7gGfa+SFgpj3JtIHBpvULbXnqvSS3tv2Hu0b6LI51B/Bc28eQJC2T1RP2/6fA15N8Bvh94GcZhM+BJDuBN4A7AarqWJIDDMLkFHBPVX3YxrkbeAy4HHi2HTDYKH8iyRyDO4mZCecrSTpPEwVFVX0P2DTm0pYztN8D7BlTnwVuHlN/nxY0kqSV4TezJUldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkromDIsmqJN9N8mvt/VVJDid5rb2uGWq7O8lckleTbB2q35LkpXbtoSRp9cuSPN3qR5Osn3S+kqTzcyHuKH4eeGXo/b3AkaraCBxp70lyIzAD3ARsAx5Osqr1eQTYBWxsx7ZW3wmcrKobgAeBBy7AfCVJ52GioEiyFvgS8CtD5e3A/na+H7h9qP5UVX1QVa8Dc8DmJNcDV1TV81VVwOMjfRbHOghsWbzbkCQtj0nvKP4d8IvAnw3Vrquq4wDt9dpWnwbeHGo332rT7Xy0flqfqjoFvAtcPeGcJUnnYclBkeSngXeq6tvn2mVMrTr1Xp/RuexKMptkdmFh4RynI0k6F5PcUfwU8OUkPwCeAv5ukv8EvN2Wk2iv77T288C6of5rgbdafe2Y+ml9kqwGrgROjE6kqvZW1aaq2jQ1NTXBR5IkjVpyUFTV7qpaW1XrGWxSP1dVPwMcAna0ZjuAZ9r5IWCmPcm0gcGm9Qtteeq9JLe2/Ye7RvosjnVH+zM+ckchSbp4Vl+EMe8HDiTZCbwB3AlQVceSHABeBk4B91TVh63P3cBjwOXAs+0AeBR4IskcgzuJmYswX0lSxwUJiqr6JvDNdv4/gC1naLcH2DOmPgvcPKb+Pi1oJEkrw29mS5K6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXUsOiiTrkvzXJK8kOZbk51v9qiSHk7zWXtcM9dmdZC7Jq0m2DtVvSfJSu/ZQkrT6ZUmebvWjSdZP8FklSUswyR3FKeBfVNVfB24F7klyI3AvcKSqNgJH2nvatRngJmAb8HCSVW2sR4BdwMZ2bGv1ncDJqroBeBB4YIL5SpKWYMlBUVXHq+o77fw94BVgGtgO7G/N9gO3t/PtwFNV9UFVvQ7MAZuTXA9cUVXPV1UBj4/0WRzrILBl8W5DkrQ8LsgeRVsS+gngKHBdVR2HQZgA17Zm08CbQ93mW226nY/WT+tTVaeAd4GrL8ScJUnnZuKgSPI54D8Dv1BV/6vXdEytOvVen9E57Eoym2R2YWHhbFOWJJ2HiYIiyZ9nEBJfr6pfbeW323IS7fWdVp8H1g11Xwu81eprx9RP65NkNXAlcGJ0HlW1t6o2VdWmqampST6SJGnEJE89BXgUeKWq/u3QpUPAjna+A3hmqD7TnmTawGDT+oW2PPVeklvbmHeN9Fkc6w7gubaPIUlaJqsn6PtTwD8CXkryvVb7V8D9wIEkO4E3gDsBqupYkgPAywyemLqnqj5s/e4GHgMuB55tBwyC6IkkcwzuJGYmmK8kaQmWHBRV9d8Yv4cAsOUMffYAe8bUZ4Gbx9TfpwWNJGllTHJHIelTav29v77SU/jU+MH9X1rpKUzMX+EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqesTERRJtiV5NclckntXej6SdCn52AdFklXAfwD+AXAj8JUkN67srCTp0vGxDwpgMzBXVb9fVX8CPAVsX+E5SdIlY/VKT+AcTANvDr2fB74w3CDJLmBXe/u/k7y6THO7FFwD/PFKT+Js8sBKz0Ar5GP/8/kJ+tn8S2e68EkIioyp1WlvqvYCe5dnOpeWJLNVtWml5yGN48/n8vgkLD3NA+uG3q8F3lqhuUjSJeeTEBQvAhuTbEjyGWAGOLTCc5KkS8bHfumpqk4l+TngG8AqYF9VHVvhaV1KXNLTx5k/n8sgVXX2VpKkS9YnYelJkrSCDApJUpdBIUnq+thvZmt5JflxBt98n2bwfZW3gENV9cqKTkzSivGOQj+U5JcY/IqUAC8weDQ5wJP+MkZ9nCX52ZWew6eZTz3ph5L8HnBTVf3pSP0zwLGq2rgyM5P6krxRVZ9f6Xl8Wrn0pGF/BvwY8Acj9evbNWnFJPmdM10CrlvOuVxqDAoN+wXgSJLX+P+/iPHzwA3Az63UpKTmOmArcHKkHuC/L/90Lh0GhX6oqn4jyV9l8Kvdpxn8BzgPvFhVH67o5CT4NeBzVfW90QtJvrnss7mEuEchSeryqSdJUpdBIUnqMigkSV0GhSSpy6CQJHX9PxLfoPWhqnZTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# откроем данные и выведем общую информацию \n",
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
    "print(df.info())\n",
    "display(df.head())\n",
    "display(df['toxic'].value_counts() / len(df['toxic']))\n",
    "df['toxic'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80285f8",
   "metadata": {},
   "source": [
    "Мы имеем данные комментариев на английском языке и целевой признак toxic, означающий токсичный ли комментарий.Изменим кодировку в тексте.\n",
    "\n",
    "В наших данных явный дисбаланс классов, метрика accuracy не подходит, так как при заполнении всех комментариев 0 у нас будет хорошое качество модели по этой метрика, но это не так. Будем использовать F1 метрику.\n",
    "\n",
    "Построим модель без борьбы с дисбалансом, если метрика будет низкая, то уже будем бороться с дисбалансом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fb31e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].values.astype('U') \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d4dfb",
   "metadata": {},
   "source": [
    "### Подготовим данные для Bert"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59710b6a",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eca78d5f",
   "metadata": {},
   "source": [
    "# Инициализируем токенизатор\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "#Преобразуем текст в номера токенов из словаря \n",
    "tokenized = df['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))\n",
    "# максимальная длина комментария\n",
    "max_len = 512 # мы выш задали этот параметр константно \n",
    "#Применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными.\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "#«создадим маску»\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ec138c4",
   "metadata": {},
   "source": [
    "model_bert = transformers.DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_bert.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf6e3787",
   "metadata": {},
   "source": [
    "# обработаем в берте наши данные\n",
    "batch_size = 1\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "  batch = torch.tensor(padded[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "  attention_mask_batch = torch.tensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "      \n",
    "  with torch.no_grad():\n",
    "    batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch)\n",
    "      \n",
    "  embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07b7f4ae",
   "metadata": {},
   "source": [
    "features_bert = np.concatenate(embeddings)\n",
    "np.save('features_bert', features_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd922bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bert = np.load('features_bert.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1dd09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной таблицы: (119678, 768)\n",
      "Размер тестовой таблицы: (39893, 768)\n"
     ]
    }
   ],
   "source": [
    "features_train_bert, features_test_bert, target_train_bert, target_test_bert = train_test_split(\n",
    "    features_bert, df['toxic'], test_size=0.25, random_state=12345) \n",
    "\n",
    "print(f\"Размер тренировочной таблицы: {features_train_bert.shape}\")\n",
    "print(f\"Размер тестовой таблицы: {features_test_bert.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ed845",
   "metadata": {},
   "source": [
    "### Подготовим данные с помощью DistilBERT base uncased finetuned SST-2\n",
    "\n",
    "Это fine-tune distilbert для определения насколько негативный/позитивный текст, модель выдает 2 параметра: negative и positive."
   ]
  },
  {
   "cell_type": "raw",
   "id": "645b668e",
   "metadata": {},
   "source": [
    "# Инициализируем токенизатор\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# Инициализируем модель\n",
    "model_bert2 = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model_bert2.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed46278f",
   "metadata": {},
   "source": [
    "#Преобразуем текст в номера токенов из словаря \n",
    "raw_inputs = list(df['text'][:1000])\n",
    "inputs = tokenizer2(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ff0a336",
   "metadata": {},
   "source": [
    "#Выведем наши параметры\n",
    "outputs = model_bert2(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6098d7a4",
   "metadata": {},
   "source": [
    "features_bert_uncased = np.concatenate(outputs)\n",
    "np.save('features_bert_uncased', features_bert_uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8c59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bert_unc = np.load('features_bert_uncased.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e247df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной таблицы: (119678, 2)\n",
      "Размер тестовой таблицы: (39893, 2)\n"
     ]
    }
   ],
   "source": [
    "features_train_bert_unc, features_test_bert_unc, target_train_bert_unc, target_test_bert_unc = train_test_split(\n",
    "    features_bert_unc, df['toxic'], test_size=0.25, random_state=12345) \n",
    "\n",
    "print(f\"Размер тренировочной таблицы: {features_train_bert_unc.shape}\")\n",
    "print(f\"Размер тестовой таблицы: {features_test_bert_unc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c44cc",
   "metadata": {},
   "source": [
    "### Подготовим данные для векторизации TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b6e1d",
   "metadata": {},
   "source": [
    "1. Отчистка\n",
    "2. Токенизация\n",
    "3. Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5726255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1538afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "def checkExecTimeMystemOneText(texts):\n",
    "    lol = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n",
    "    txtpart = lol(texts, 10000)\n",
    "    res = []\n",
    "    for txtp in txtpart:\n",
    "        alltexts = ' '.join([txt + ' brnew ' for txt in txtp])\n",
    "        raw_txt = re.sub(r'[^a-zA-Z ]', ' ', alltexts)\n",
    "        words = m.lemmatize(\" \".join(raw_txt.split()))\n",
    "        doc = []\n",
    "        for txt in words:\n",
    "            if txt.strip() != '':\n",
    "                if txt == 'brnew':\n",
    "                    res.append(\" \".join(doc))\n",
    "                    doc = []\n",
    "                else:\n",
    "                    doc.append(txt)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0eed30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemm_text = checkExecTimeMystemOneText(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8000528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   text       159571 non-null  object\n",
      " 1   toxic      159571 non-null  int64 \n",
      " 2   lemm_text  159571 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data['lemm_text'] = lemm_text\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd08c9",
   "metadata": {},
   "source": [
    "**Векторизация TF-IDF**\n",
    "\n",
    "Дополнительно избавимся от стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641513da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выдлим стоп-слова\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "411497c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочных данных: 119678\n",
      "Размер тестовых данных: 39893\n"
     ]
    }
   ],
   "source": [
    "# Разобьем данные на тестовую и тренировочную выборки \n",
    "corpus_train, corpus_test, target_train, target_test = train_test_split(\n",
    "    data['lemm_text'], data['toxic'], test_size=0.25, random_state=12345)\n",
    "print(f\"Размер тренировочных данных: {len(corpus_train)}\")\n",
    "print(f\"Размер тестовых данных: {len(corpus_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39d6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем векторизацию\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(corpus_train)\n",
    "features_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a88c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной таблицы: (119678, 143178)\n",
      "Размер тестовой таблицы: (39893, 143178)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размер тренировочной таблицы: {features_train.shape}\")\n",
    "print(f\"Размер тестовой таблицы: {features_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fda92",
   "metadata": {},
   "source": [
    "### Подготовим данные catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76c6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные на обучающую, валидационнуб выборку и тестовую 3:1:1\n",
    "train_cb, prom_cb = train_test_split(data, test_size=0.4, random_state=12345)\n",
    "valid_cb, test_cb = train_test_split(prom_cb, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa9646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=train_cb['lemm_text'].values, label=train_cb['toxic'].values, text_features=[0])\n",
    "valid_pool = Pool(data=valid_cb['lemm_text'].values, label=valid_cb['toxic'].values, text_features=[0])\n",
    "test_pool = Pool(data=test_cb['lemm_text'].values, label=test_cb['toxic'].values, text_features=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e48ca6",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c887320",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "В нашем распоряжении комментарии пользователей с разметкой о токсичности. Комментарии на английском языке, имеется значительный дисбаланс классов, но пока не будем его поправлять, попробуем так обучить модель. \n",
    "\n",
    "Данные раздлили на выборки данные Bert я подготавливал в гугл колаб на GPU. Их преобразование занимает 1,5 часа.\n",
    "\n",
    "Далее создадим модели предсказаний, обучим их и протестируем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3adcf",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38363114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем использовать только логистическую регрессию с балансировкой классов и без\n",
    "# Создадим функцию\n",
    "def logreg(features_train, features_test, target_train, target_test):\n",
    "    lr = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "    lr.fit(features_train, target_train)  # обучим модель\n",
    "    pred_test = lr.predict(features_test)  # предсказывания\n",
    "    acc = lr.score(features_test, target_test)\n",
    "    f1=f1_score(\n",
    "        target_test, pred_test, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
    "    print('Точность без баланса: ',acc)  # правильность модели\n",
    "    print('F1 без баланса: ',f1)\n",
    "    \n",
    "    lr_b = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "    lr_b.fit(features_train, target_train)  # обучим модель\n",
    "    pred_test_b = lr_b.predict(features_test)  # предсказывания\n",
    "    acc_b = lr_b.score(features_test, target_test)\n",
    "    f1_b=f1_score(\n",
    "        target_test, pred_test_b, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
    "    print('Точность c балансом классов: ',acc_b)  # правильность модели\n",
    "    print('F1 c балансом классов: ',f1_b)\n",
    "    \n",
    "    if f1 > f1_b:\n",
    "        return lr, acc, f1\n",
    "    return lr_b, acc_b, f1_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ba579",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea96b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность без баланса:  0.9530243401097936\n",
      "F1 без баланса:  0.7439890710382513\n",
      "Точность c балансом классов:  0.9092572631790038\n",
      "F1 c балансом классов:  0.6697080291970803\n"
     ]
    }
   ],
   "source": [
    "lr_bert, acc_bert, f1_bert = logreg(\n",
    "    features_train_bert, features_test_bert, target_train_bert, target_test_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23bc12",
   "metadata": {},
   "source": [
    "### DistilBERT base uncased finetuned SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e8a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность без баланса:  0.8975509487880079\n",
      "F1 без баланса:  0.0\n",
      "Точность c балансом классов:  0.4246108339808989\n",
      "F1 c балансом классов:  0.2180814824908026\n"
     ]
    }
   ],
   "source": [
    "lr_bert_unc, acc_bert_unc, f1_bert_unc = logreg(\n",
    "    features_train_bert_unc, features_test_bert_unc, target_train_bert_unc, target_test_bert_unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a4dff",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b528636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность без баланса:  0.9554057102749856\n",
      "F1 без баланса:  0.7367953839325344\n",
      "Точность c балансом классов:  0.944401273406362\n",
      "F1 c балансом классов:  0.7588081774684645\n"
     ]
    }
   ],
   "source": [
    "lr, acc, f1 = logreg(\n",
    "    features_train, features_test, target_train, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36c298",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089c7331",
   "metadata": {},
   "source": [
    "###  Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b2ab04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим функцию модели\n",
    "def fit_model(train_pool, test_pool, **kwargs):\n",
    "    model = CatBoostClassifier(\n",
    "        #task_type='GPU',\n",
    "        loss_function='Logloss',\n",
    "        iterations=1000, #1000\n",
    "        eval_metric='F1',\n",
    "        od_type='Iter',\n",
    "        early_stopping_rounds=200,\n",
    "        **kwargs)\n",
    "    return model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        verbose= 200, #200\n",
    "        plot=True,\n",
    "        use_best_model=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0ab2ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d5a9ccacf3435bbed4a6c584304409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3653910\ttest: 0.3757097\tbest: 0.3757097 (0)\ttotal: 677ms\tremaining: 11m 16s\n",
      "200:\tlearn: 0.7571622\ttest: 0.7335296\tbest: 0.7335296 (200)\ttotal: 2m 4s\tremaining: 8m 13s\n",
      "400:\tlearn: 0.7991212\ttest: 0.7566119\tbest: 0.7567471 (399)\ttotal: 3m 33s\tremaining: 5m 19s\n",
      "600:\tlearn: 0.8248614\ttest: 0.7668193\tbest: 0.7680649 (584)\ttotal: 4m 57s\tremaining: 3m 17s\n",
      "800:\tlearn: 0.8388886\ttest: 0.7739343\tbest: 0.7742048 (798)\ttotal: 6m 23s\tremaining: 1m 35s\n",
      "999:\tlearn: 0.8510882\ttest: 0.7774883\tbest: 0.7779128 (988)\ttotal: 7m 46s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7779128321\n",
      "bestIteration = 988\n",
      "\n",
      "Shrink model to first 989 iterations.\n"
     ]
    }
   ],
   "source": [
    "model_cb = fit_model(\n",
    "    train_pool, valid_pool,\n",
    "    learning_rate=0.15, #0.15\n",
    "    tokenizers=[\n",
    "        {\n",
    "            #'lemmatizing': 'True', # не реализован ((\n",
    "            #'number_process_policy': 'Skip',\n",
    "            'tokenizer_id': 'Sense',\n",
    "            'separator_type': 'BySense',\n",
    "            'lowercasing': 'True',\n",
    "            'token_types': ['Word', 'Number', 'SentenceBreak'],\n",
    "            'sub_tokens_policy':'SeveralTokens'\n",
    "        }      \n",
    "    ],\n",
    "    dictionaries = [\n",
    "        {\n",
    "            'dictionary_id': '[Word]',\n",
    "            'max_dictionary_size': '100000'\n",
    "        }\n",
    "    ],\n",
    "    feature_calcers = [\n",
    "        'BoW:top_tokens_count=10000'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f08610",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cb = model_cb.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3089c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность:  0.959016136612878\n",
      "F1:  0.7682494684620836\n"
     ]
    }
   ],
   "source": [
    "acc_cb = model_cb.score(test_pool)\n",
    "f1_cb = f1_score(\n",
    "    test_cb['toxic'], predict_cb, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
    "print('Точность: ',acc_cb)  # правильность модели\n",
    "print('F1: ',f1_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f10ba",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e82fcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBERT</th>\n",
       "      <td>0.743989</td>\n",
       "      <td>0.953024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBERT finetuned</th>\n",
       "      <td>0.218081</td>\n",
       "      <td>0.424611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.758808</td>\n",
       "      <td>0.944401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catboost</th>\n",
       "      <td>0.768249</td>\n",
       "      <td>0.959016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            F1  Accuracy\n",
       "DistilBERT            0.743989  0.953024\n",
       "DistilBERT finetuned  0.218081  0.424611\n",
       "TF-IDF                0.758808  0.944401\n",
       "Catboost              0.768249  0.959016"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Построим таблицу с результатами качества различных методов\n",
    "index_models=['DistilBERT',\n",
    "              'DistilBERT finetuned',\n",
    "              'TF-IDF',\n",
    "              'Catboost']\n",
    "f1_models = pd.Series([f1_bert, f1_bert_unc, f1, f1_cb], \n",
    "                   index=index_models\n",
    "                  )\n",
    "acc_models = pd.Series([acc_bert, acc_bert_unc, acc, acc_cb], \n",
    "                   index=index_models\n",
    "                  )\n",
    "output = pd.DataFrame({'F1': f1_models, 'Accuracy': acc_models})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66c81c",
   "metadata": {},
   "source": [
    "**Модель, которая предсказывает одни лишь нетоксичные комментарии показывает accuracy 0.898.**\n",
    "\n",
    "Облегчнный берт показывает плохое качество, его следует дообучить на наших данных, но colab ограничивает ресурсы, поэтому в реальной работе этим займусь.\n",
    "\n",
    "Модель берта заточенная на определения негативных прдложений показала себя отвратитльно, скорее всего я где-то что-то упустил, потому что на сайте https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english?text=COCKSUCKER+BEFORE+YOU+PISS+AROUND+ON+MY+WORK модель правильно определяет негатив, а у меня н показывает негатива.\n",
    "\n",
    "После обработки тестов с помощью метода TF-IDF и дальнейшего балансирования весов классов в модели линейной регрессии у нас получился результат, который требуется по заданию, а именно 0,759. То есть такая простая и быстрая система выявления токсичных комментариев отлично себя показала и может быть принятой в работу.\n",
    "\n",
    "Модель градиеентного бустинга catboost к сожалнию еще не поддерживает лемматизацию, поэтому мы обучали и тестиовалии на заранее отлемматизированных комментариях. Модель довольно быстро обучилась, около 10 минут и показала хороший результат в 0,768. Если ее усложнить и подключить обучение на GPU то можно получить результат лучше при той же скорости. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d27fa",
   "metadata": {},
   "source": [
    "##  Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb5673",
   "metadata": {},
   "source": [
    "Около 10% всех комментариев являются токсичными, что очень усложняет жизнь модераторам и отнимает их драгоценное время. \n",
    "\n",
    "Для упрощения жизни модераторам в поисках токсичных комментариев, мы построили несколько моделей выявления этих комментариев и вычислили их F1 метрику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aa109ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistilBERT</th>\n",
       "      <td>0.743989</td>\n",
       "      <td>0.953024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistilBERT finetuned</th>\n",
       "      <td>0.218081</td>\n",
       "      <td>0.424611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.758808</td>\n",
       "      <td>0.944401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catboost</th>\n",
       "      <td>0.768249</td>\n",
       "      <td>0.959016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            F1  Accuracy\n",
       "DistilBERT            0.743989  0.953024\n",
       "DistilBERT finetuned  0.218081  0.424611\n",
       "TF-IDF                0.758808  0.944401\n",
       "Catboost              0.768249  0.959016"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbdf3d3",
   "metadata": {},
   "source": [
    "При ограниченных ресурсах, например, отсуствие GPU следут брать модель, построенну на векторизации текста с последующей прогонкой через модель логистической регрессии для выявления признака токсичности. Такая модель показывает результат выше заданного порога. У модели 0,759, а порог 0,75.\n",
    "\n",
    "При среднем желзе следует катбуст, а при хорошем железе следует смотреть в сторону разделния выдления признаков текста через Bert с дообучением на текущих данных, с построением модели градиентного бустинга в catboost. Как правило такие сложные системы очень эффективны и позволят снизить количество модераторов, а соотвественно и снизить зарплатную нагрузку и человеческий фактор."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Оглавление",
   "title_sidebar": "Оглавление",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
